{
 "metadata": {
  "name": "",
  "signature": "sha256:7820003586720b9348a670f0e8a9cb92cdad1882dde7a06849744c25dd183e16"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Classification of physical activities using Athos EMG-sensor garments"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.display import HTML\n",
      "HTML('athospy/show_hide_code.html')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<script>\n",
        "// var code_show=false; \n",
        "$('div.input').hide();\n",
        "$('div.prompt').hide();\n",
        "\n",
        "function code_toggle() {\n",
        " \tif (code_show){\n",
        " \t\t$('div.input').hide();\n",
        " \t} else {\n",
        " \t\t$('div.input').show();\n",
        " \t}\n",
        " \tcode_show = !code_show\n",
        "} \n",
        "\n",
        "$( document ).ready(code_toggle);\n",
        "</script>\n",
        "\n",
        "<a href=\"javascript:code_toggle()\">Click here</a> to toggle the display of code.\n"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 37,
       "text": [
        "<IPython.core.display.HTML at 0x1109a2090>"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<!-- Abstract / executive summary here -->\n",
      "<!-- background -->\n",
      "\n",
      "*\n",
      "The abilty to quantify an individual's level of physical activity is a major challenge in personal health and fitness.\n",
      "  Although heartrate monitors and step counters have exsited for decades, devices [and data systems] for measuring how well a patient's or athlete's muscles and joints function [have been lacking].  \n",
      "...  \n",
      "Athos, is making a significant step towards [a solution to this problem]\n",
      "A key challenge in the [area] physical health, wellness, and fitness is being able to quantitatively  \n",
      "...  \n",
      "*\n",
      "\n",
      "- background (include product relevance)\n",
      "- objectives\n",
      "- results\n",
      "- discussion\n",
      "\n",
      "<!-- other introductory remarks -->\n",
      "\n",
      "A major component of data science is asking the right questions (especially \"Why?\").\n",
      "See [Mark's question list (link)]() to get a glimpse of the kind of questions I asked while working on this awesome project.\n",
      "\n",
      "First, we'll [clean up the raw data](#Data-preparation) and parse out any useful metadata from file names, folder names, and `README` contents.\n",
      "Than, we'll do some [exploratory analysis](#Exploratory-analysis) to identify some quantitative features of the data we can use to explain differences in muscle activity between different exercises and people.\n",
      "After that, we'll develop a [[statistical model]](#Model-development) model that classifies physical activities.\n",
      "Finally we'll [test and validate that model](#Testing-and-validation) and compare its performane to the state of the art.\n",
      "\n",
      "High-level function calls and some example code is included in this post and can be shown/hidden by clicking on the \"show/hide\" link at the top of the page."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# import modules and set display configuration\n",
      "from athospy import modules # call other import statements\n",
      "import athospy.my_fcns as my"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Data preparation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The first step in executing a data science project (after obtaining the data, of course) is \"data cleaning\".\n",
      "\n",
      "* parse out labels (person, exercise, leg side, other...) from data folders and CSV files\n",
      "* inspect some of the data to see what we're working with\n",
      "* identify experiment files with potentially corrupt data\n",
      "* summarize the dataset\n",
      "* select portions of the data for training/testing/validation"
     ]
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Parsing"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# load a dataset provided by Athos (proprietary, of course)\n",
      "# use regular expressions to parse out labels from file/folder names\n",
      "# files/folders with unconventional naming patterns are logged, but not included\n",
      "DATA_DIR = '../data/Research-Sessions/'\n",
      "\n",
      "folders = my.parse_labels(DATA_DIR, 'blasdf') # folder names contain person-labels\n",
      "files  = [my.parse_labels(subdir, 'asdf') for subdir in folders.path]\n",
      "\n",
      "# print 'Ignored %d data folders and %d data files due to parsing errors' % (len(folders_ign), len(files_ign))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'parse_labels' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-38-425d6c4031f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mDATA_DIR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../data/Research-Sessions/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mfolders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'blasdf'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# folder names contain person-labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles_ign\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mparse_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'asdf'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfolders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'parse_labels' is not defined"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Inspection"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# inspect some of the data for the 1st individual in the list\n",
      "stairs_eg = files[('Exercise'=='Stairs') && 'Person'==1)]\n",
      "bblaster_eg = files[('Exercise'=='ButtBlaster') && 'Person'==1)]\n",
      "\n",
      "my.plot_EMG(files[is_exer && is_person])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Cleaning"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# exclude and document files with problematic-looking data\n",
      "files_clean = my.exclude_files_by(files, 'path/to/cleaning-config')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# visualize the distribution of examplars across persons and exercises\n",
      "# select subsets of the data for model development/testing validation\n",
      "files_train, files_test = my.select_subset(files)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'select_subset' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-39-34e3f4eed51e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# visualize the distribution of examplars across persons and exercises\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# select subsets of the data for model development/testing validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfiles_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_subset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mNameError\u001b[0m: name 'select_subset' is not defined"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# sample data from each file, centered around the middle of each experiment\n",
      "n_secs = 10\n",
      "data_train = my.sample_data(files_train, n_secs)\n",
      "data_test = my.sample_data(files_test, n_secs)\n",
      "# these are dictionaries of data, indexed by file name"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Exploratory analysis"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "After 'cleaning' the dataset and making sure that we understand the meaning of all the variables and labels, we can start some exploratory data analysis.\n",
      "\n",
      "* selecting features to characterize the EMG signals\n",
      "* distribution of features, and normalization/transformation if needed\n",
      "* relationships between features\n",
      "* dimensionality reduction / feature selection"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# use the EMG signal from the right outside quadriceps muscle as an example\n",
      "signal = stairs.RVL.values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "EMG signal maxima (muscle contraction)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# mean values above half-maximum (more robust than peak detection)\n",
      "is_peak = (signal > 0.5 * signal.max())\n",
      "\n",
      "plt.plot(signal)\n",
      "plt.plot(is_peak, signal)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Frequency components (tempo)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# apply fourier transform and plot frequency components\n",
      "fft_out = abs(np.fft.rfft(signal))\n",
      "freq = np.fft.rfftreq(len(signal), d=1/41.7)\n",
      "\n",
      "plt.plot(freq, fft_out)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Pairwise phase shift between signals (timing)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# cross correlation to calculate phase lag between left and right channels\n",
      "signal2 = stairs.LVL.values\n",
      "nsamp = len(signal2)\n",
      "\n",
      "xcorr = correlate(signal, signal2)\n",
      "dt = np.arange(1-nsamp, nsamp)b\n",
      "\n",
      "plt.plot(dt, xcorr);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# calculate features across files and standardize them\n",
      "features_train = calc_features(data_train, standardize=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Model development"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that we've selected some features that seem to characterize the data, we can use them as inputs to a statistical model, that [...]\n",
      "\n",
      "* trying out a couple models on a small-to-medium size dataset\n",
      "* rationale for choosing a model"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Testing and validation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Great, we've got a model that does a fairly good job of predicting the kind of activity an individual is doing.\n",
      "Now we can try to optimize model performance and finally validate it on an unseen dataset."
     ]
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Measuring and optimizing performance of the model"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* optimizing model parameters (improvement in results)\n",
      "* data cleaning\n",
      "* adding R/L labels\n",
      "* changing window length"
     ]
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "applying the model to an unseen dataset"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* leave-one-out validation?\n",
      "* other cross validation methods?"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Implications"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Non-linear, multivariate time series analysis in both the time and frequency domains.  \n",
      "...can be applied to other data problems involving time series, related to clustering, classification, forecasting, and anomaly detection."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Next steps and future work"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "OK, in this post we've gone through the whole pipeline of a prototypical data science project, from data cleaning to validation of a predictive model--but there's always more work to be done!\n",
      "Below are some potential areas of improvement, along with some preliminary results that can help us gauge their value.\n",
      "\n",
      "<!-- improvements -->\n",
      "\n",
      "* Did cleaning the data improve the results? How do we automate or fix this for future datasets?\n",
      "* Could accelerometer data improve activity classification?\n",
      "* How can activity classification benefit users? What other DataSci techniques could provide value?\n",
      "* increasing the number of activities?"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}